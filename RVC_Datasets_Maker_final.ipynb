{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title RVC Dataset Maker (All-in-One)\n",
        "#====================================================================================\n",
        "# @markdown # 1. USER CONFIGURATION\n",
        "# @markdown ### Fill in all your project details here before running the script.\n",
        "#====================================================================================\n",
        "\n",
        "# @markdown **Select the main operation mode and the source of your audio.**\n",
        "# @markdown - `Splitting`: Separates vocals, then cuts them into a dataset.\n",
        "# @markdown - `Separate`: Only separates vocals from music.\n",
        "mode = \"Splitting\"  #@param [\"Splitting\", \"Separate\"]\n",
        "dataset = \"Drive\"  #@param [\"Youtube\", \"Drive\"]\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown **Fill in the source URL or Drive Path.**\n",
        "# @markdown - If using Drive, right-click your file in Colab's file browser and \"Copy path\".\n",
        "url = \"\"  #@param {type:\"string\"}\n",
        "drive_path = \"/content/drive/MyDrive/fuyumi_elsa/fuyumi_elsa_mentah.wav\"  #@param {type:\"string\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown **Define a project name and output format.**\n",
        "# @markdown - `audio_name`: A unique name for your project folders.\n",
        "# @markdown - `output_sr`: The sample rate for the output. 32000 is good for RVC. '0' keeps the original.\n",
        "audio_name = \"fuyumi_elsa_dataset2\"  #@param {type:\"string\"}\n",
        "output_sr = \"44100\"  #@param [\"0\", \"8000\", \"16000\", \"22050\", \"32000\", \"44100\", \"48000\"]\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown **Advanced Settings (Optional)**\n",
        "# @markdown - `demucs_model`: The AI model for vocal separation. `htdemucs` is recommended.\n",
        "# @markdown - `chunk_duration_seconds`: Splits very long audio files into chunks of this duration (in seconds) to avoid memory errors.\n",
        "demucs_model = \"htdemucs\"  #@param [\"htdemucs\", \"demucs\", \"demucs_extra\", \"htdemucs_ft\"]\n",
        "chunk_duration_seconds = 1800  #@param {type:\"number\"}\n",
        "\n",
        "# @markdown - `Slicer Settings` (for 'Splitting' mode only): Controls how the vocal track is cut. Defaults are usually effective.\n",
        "threshold = -40  #@param {type:\"slider\", min:-60, max:-20, step:1}\n",
        "min_length = 5000  #@param {type:\"number\"}\n",
        "min_interval = 300  #@param {type:\"number\"}\n",
        "hop_size = 10 #@param {type:\"number\"}\n",
        "max_sil_kept = 500 #@param {type:\"number\"}\n",
        "\n",
        "#====================================================================================\n",
        "# SCRIPT EXECUTION - NO NEED TO EDIT BELOW THIS LINE\n",
        "#====================================================================================\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import shlex\n",
        "import glob\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "def run_command(command, error_message):\n",
        "    \"\"\"Runs a shell command and prints output in real-time.\"\"\"\n",
        "    process = subprocess.Popen(shlex.split(command), stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, encoding='utf-8')\n",
        "    while True:\n",
        "        output = process.stdout.readline()\n",
        "        if output == '' and process.poll() is not None:\n",
        "            break\n",
        "        if output:\n",
        "            print(output.strip())\n",
        "    rc = process.poll()\n",
        "    if rc != 0:\n",
        "        print(f\"âŒ ERROR: {error_message} (Exit Code: {rc})\")\n",
        "        raise subprocess.CalledProcessError(rc, command)\n",
        "\n",
        "try:\n",
        "    # --- 2. SETUP AND VALIDATION ---\n",
        "    print(\"STEP 2: Mounting Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"\\nSTEP 2: Validating parameters...\")\n",
        "    if not audio_name.strip():\n",
        "        raise ValueError(\"'audio_name' cannot be empty.\")\n",
        "    if dataset == \"Youtube\" and not url.strip():\n",
        "        raise ValueError(\"'url' cannot be empty for Youtube mode.\")\n",
        "    if dataset == \"Drive\" and not drive_path.strip():\n",
        "        raise ValueError(\"'drive_path' cannot be empty for Drive mode.\")\n",
        "    if dataset == \"Drive\" and not os.path.exists(drive_path):\n",
        "        raise FileNotFoundError(f\"File not found at 'drive_path': {drive_path}\")\n",
        "    output_sr_int = int(output_sr)\n",
        "    print(\"âœ… Parameters validated successfully.\")\n",
        "\n",
        "    # --- 3. INSTALL DEPENDENCIES ---\n",
        "    print(\"\\nSTEP 3: Installing all required libraries...\")\n",
        "    install_command = \"python3 -m pip install --upgrade demucs yt-dlp ffmpeg-python librosa soundfile numpy --quiet\"\n",
        "    subprocess.check_call(shlex.split(install_command))\n",
        "    import numpy as np\n",
        "    import librosa\n",
        "    import soundfile as sf\n",
        "    print(\"âœ… All libraries installed.\")\n",
        "\n",
        "    # --- 4. PREPARE AUDIO INPUT ---\n",
        "    print(\"\\nSTEP 4: Preparing audio input...\")\n",
        "    audio_input = \"\"\n",
        "    if dataset == \"Youtube\":\n",
        "        import yt_dlp\n",
        "        print(f\"Downloading from YouTube URL: {url}\")\n",
        "        os.makedirs(\"youtube_audio\", exist_ok=True)\n",
        "        ydl_opts = {\n",
        "            'format': 'bestaudio/best',\n",
        "            'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'wav'}],\n",
        "            'outtmpl': f'youtube_audio/{audio_name}.%(ext)s',\n",
        "        }\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([url])\n",
        "        audio_input = os.path.abspath(f\"youtube_audio/{audio_name}.wav\")\n",
        "    else: # Drive\n",
        "        audio_input = os.path.abspath(drive_path)\n",
        "\n",
        "    if not os.path.exists(audio_input):\n",
        "        raise FileNotFoundError(f\"Audio input file not found: {audio_input}\")\n",
        "    print(f\"âœ… Audio input ready: {audio_input}\")\n",
        "\n",
        "    # --- 5. VOCAL SEPARATION (DEMUCS) ---\n",
        "    print(\"\\nSTEP 5: Starting vocal separation...\")\n",
        "    duration = librosa.get_duration(path=audio_input)\n",
        "    print(f\"Audio duration: {duration:.2f} seconds.\")\n",
        "    output_dir = os.path.abspath(f\"separated/{demucs_model}/{audio_name}\")\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    vocals_final_path = os.path.join(output_dir, \"vocals.wav\")\n",
        "\n",
        "    if duration > chunk_duration_seconds:\n",
        "        # Logic for long files\n",
        "        print(f\"Audio is long. Splitting into {chunk_duration_seconds}s chunks...\")\n",
        "        chunks_dir = os.path.abspath(\"temp_chunks\")\n",
        "        os.makedirs(chunks_dir, exist_ok=True)\n",
        "        split_cmd = f'ffmpeg -hide_banner -loglevel error -i \"{audio_input}\" -f segment -segment_time {chunk_duration_seconds} -c copy \"{chunks_dir}/{audio_name}_%03d.wav\"'\n",
        "        run_command(split_cmd, \"Failed to split audio into chunks.\")\n",
        "\n",
        "        chunk_files = sorted(glob.glob(f\"{chunks_dir}/{audio_name}_*.wav\"))\n",
        "        vocals_from_chunks = []\n",
        "        for idx, chunk_file in enumerate(chunk_files):\n",
        "            print(f\"--- Processing Chunk {idx+1}/{len(chunk_files)} ---\")\n",
        "            demucs_cmd = f'python3 -m demucs.separate --two-stems vocals --name {demucs_model} -o \"separated\" \"{chunk_file}\"'\n",
        "            run_command(demucs_cmd, f\"Demucs failed on chunk {idx+1}.\")\n",
        "            base = os.path.splitext(os.path.basename(chunk_file))[0]\n",
        "            expected_vocal_path = os.path.abspath(f\"separated/{demucs_model}/{base}/vocals.wav\")\n",
        "            if os.path.exists(expected_vocal_path):\n",
        "                vocals_from_chunks.append(expected_vocal_path)\n",
        "\n",
        "        concat_list_file = \"vocals_list.txt\"\n",
        "        with open(concat_list_file, \"w\") as f:\n",
        "            for v_file in vocals_from_chunks:\n",
        "                f.write(f\"file '{v_file}'\\n\")\n",
        "\n",
        "        print(\"Stitching vocal chunks back together...\")\n",
        "        concat_cmd = f'ffmpeg -hide_banner -loglevel error -f concat -safe 0 -i \"{concat_list_file}\" -c copy \"{vocals_final_path}\"'\n",
        "        run_command(concat_cmd, \"Failed to concatenate vocal chunks.\")\n",
        "    else:\n",
        "        # Logic for short files\n",
        "        print(\"Processing full audio file with Demucs...\")\n",
        "        demucs_cmd = f'python3 -m demucs.separate --two-stems vocals --name {demucs_model} -o \"separated\" --filename \"{audio_name}/{{stem}}.{{ext}}\" \"{audio_input}\"'\n",
        "        run_command(demucs_cmd, \"Demucs separation process failed.\")\n",
        "\n",
        "    if not os.path.exists(vocals_final_path):\n",
        "        raise FileNotFoundError(f\"Vocal separation failed. Final vocal file not found: {vocals_final_path}\")\n",
        "    print(\"âœ… Vocal separation complete!\")\n",
        "\n",
        "    # --- 6. SLICE DATASET ---\n",
        "    if mode == \"Splitting\":\n",
        "        print(\"\\nSTEP 6: Slicing vocal track into dataset...\")\n",
        "        # Slicer class from original notebook\n",
        "        class Slicer:\n",
        "            def __init__(self, sr: int, threshold: float, min_length: int, min_interval: int, hop_size: int, max_sil_kept: int):\n",
        "                if not min_length >= min_interval >= hop_size: raise ValueError('min_length >= min_interval >= hop_size')\n",
        "                if not max_sil_kept >= hop_size: raise ValueError('max_sil_kept >= hop_size')\n",
        "                self.sr, self.threshold = sr, 10**(threshold/20.)\n",
        "                self.hop_size, self.win_size = round(sr*hop_size/1000), min(round(sr*min_interval/1000), 4*round(sr*hop_size/1000))\n",
        "                self.min_length, self.min_interval, self.max_sil_kept = round(sr*min_length/1000/self.hop_size), round(min_interval/1000/self.hop_size), round(sr*max_sil_kept/1000/self.hop_size)\n",
        "            def _get_rms(self, y, **kwargs):\n",
        "                return librosa.feature.rms(y=y, **kwargs)\n",
        "            def slice(self, waveform):\n",
        "                rms_list = self._get_rms(y=waveform, frame_length=self.win_size, hop_length=self.hop_size)[0]\n",
        "                sil_tags, silence_start, clip_start = [], None, 0\n",
        "                for i, rms in enumerate(rms_list):\n",
        "                    if rms < self.threshold:\n",
        "                        if silence_start is None: silence_start = i\n",
        "                        continue\n",
        "                    if silence_start is None: continue\n",
        "                    is_leading_silence, need_slice_middle = silence_start == 0 and i > self.max_sil_kept, (i - silence_start >= self.min_interval and i - clip_start >= self.min_length)\n",
        "                    if not is_leading_silence and not need_slice_middle:\n",
        "                        silence_start = None\n",
        "                        continue\n",
        "                    if i - silence_start <= self.max_sil_kept:\n",
        "                        pos = rms_list[silence_start:i+1].argmin()+silence_start\n",
        "                        sil_tags.append((0,pos) if silence_start==0 else (pos,pos))\n",
        "                        clip_start = pos\n",
        "                    else:\n",
        "                        pos_l, pos_r = rms_list[silence_start:silence_start+self.max_sil_kept+1].argmin()+silence_start, rms_list[i-self.max_sil_kept:i+1].argmin()+i-self.max_sil_kept\n",
        "                        sil_tags.append((0,pos_r) if silence_start==0 else (pos_l,pos_r))\n",
        "                        clip_start = pos_r\n",
        "                    silence_start = None\n",
        "                total_frames = len(rms_list)\n",
        "                if silence_start is not None and total_frames - silence_start >= self.min_interval:\n",
        "                    sil_tags.append((rms_list[silence_start:total_frames+1].argmin()+silence_start, total_frames+1))\n",
        "                if not sil_tags: return [waveform]\n",
        "                chunks = []\n",
        "                if sil_tags[0][0] > 0: chunks.append(waveform[:sil_tags[0][0]*self.hop_size])\n",
        "                for i in range(len(sil_tags)-1): chunks.append(waveform[sil_tags[i][1]*self.hop_size:sil_tags[i+1][0]*self.hop_size])\n",
        "                if sil_tags[-1][1]*self.hop_size < len(waveform): chunks.append(waveform[sil_tags[-1][1]*self.hop_size:])\n",
        "                return chunks\n",
        "\n",
        "        load_sr = None if output_sr_int == 0 else output_sr_int\n",
        "        audio, sr = librosa.load(vocals_final_path, sr=load_sr, mono=True)\n",
        "        final_sr = sr if output_sr_int == 0 else output_sr_int\n",
        "        slicer = Slicer(sr=final_sr, threshold=threshold, min_length=min_length, min_interval=min_interval, hop_size=hop_size, max_sil_kept=max_sil_kept)\n",
        "        chunks = slicer.slice(audio)\n",
        "        dataset_dir = os.path.abspath(f\"dataset/{audio_name}\")\n",
        "        os.makedirs(dataset_dir, exist_ok=True)\n",
        "        saved_chunks = 0\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            if len(chunk) / final_sr < 0.1: continue\n",
        "            sf.write(f\"{dataset_dir}/split_{i:04d}.wav\", chunk, final_sr)\n",
        "            saved_chunks += 1\n",
        "        print(f\"âœ… Splitting complete. {saved_chunks} chunks saved.\")\n",
        "    else:\n",
        "        print(\"\\nSTEP 6: Mode is 'Separate'. Skipping slicing.\")\n",
        "\n",
        "    # --- 7. SAVE TO GOOGLE DRIVE ---\n",
        "    print(\"\\nSTEP 7: Copying all results to Google Drive...\")\n",
        "    drive_separated_dest = f\"/content/drive/MyDrive/RVC_Datasets/{audio_name}\"\n",
        "    print(f\"Copying separated audio to: {drive_separated_dest}\")\n",
        "    shutil.copytree(output_dir, drive_separated_dest, dirs_exist_ok=True)\n",
        "    if mode == \"Splitting\":\n",
        "        source_dataset_folder = os.path.abspath(f\"dataset/{audio_name}\")\n",
        "        drive_dataset_dest = f\"/content/drive/MyDrive/RVC_Datasets/{audio_name}_sliced\"\n",
        "        if os.path.exists(source_dataset_folder):\n",
        "            print(f\"Copying sliced dataset to: {drive_dataset_dest}\")\n",
        "            shutil.copytree(source_dataset_folder, drive_dataset_dest, dirs_exist_ok=True)\n",
        "\n",
        "    print(\"\\n\\nðŸŽ‰ All processes are complete! Check your Google Drive for the results.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"\\n\" + \"=\"*20 + \" A FATAL ERROR OCCURRED \" + \"=\"*20)\n",
        "    print(\"The script stopped due to an error. Please review the messages above.\")\n",
        "    # Re-raise the exception to show the full traceback in Colab\n",
        "    raise e"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6kU34DIiQ9wu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}